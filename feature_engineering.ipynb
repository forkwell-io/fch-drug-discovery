{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import re\n",
    "import os\n",
    "import deepsmiles\n",
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import biovec\n",
    "from mypackages.smilesvec import *\n",
    "from mypackages.deepchem import *\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "and somemore cleaning lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/preprocessing/clean_bindingdb.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['id', 'ligand_smiles', 'target_name', 'Ki', 'Ki_r', 'IC50', 'IC50_r', 'Kd_r', 'Kd', 'EC50', 'EC50_r', 'pH', 'temp', 'n_protein_chains']\n",
    "for i in range(1, 20):\n",
    "    col.append('chain_' + str(i))\n",
    "col.append('molwt')\n",
    "df.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Ki_r', 'IC50_r', 'Kd_r', 'EC50_r']].fillna(0, inplace=True)\n",
    "df['pH'].fillna(-1, inplace=True)\n",
    "df['temp'] = pd.to_numeric(df.temp.str.replace('C', '').fillna(-1))\n",
    "types = {'id': np.int32, 'Ki_r': np.int8, 'IC50_r': np.int8, 'Kd_r': np.int8, 'EC50_r': np.int8, 'pH': np.float16, 'temp': np.float16, 'molwt': np.float16}\n",
    "df = df.astype(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 20):\n",
    "    df['chain_' + str(i)] = df['chain_' + str(i)].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_target = ~df.chain_1.isnull() #checking whether the entry having at least one target, the dataset is a real mess, n_protein_chains is not accurate =(\n",
    "for i in range(2, 20):\n",
    "    has_target = has_target | (~df['chain_'+str(i)].isnull())\n",
    "\n",
    "df = df[has_target]\n",
    "df.dropna(subset=['ligand_smiles'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_col_name = ['chain_'+str(i) for i in range(1, 20)]\n",
    "pv_col_name = ['pv_'+str(i) for i in range(1, 101)]\n",
    "sv_col_name = ['sv_'+str(i) for i in range(1, 101)]\n",
    "dc_col_name = ['dc_'+str(i) for i in range(1, 112)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, chain_col_name] = df[chain_col_name].fillna('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df.chain_1.str.contains('\\d', na=False)) & (df.chain_1 != '-1'))]\n",
    "df = df[~((df.chain_2.str.contains('\\d', na=False)) & (df.chain_2 != '-1'))]\n",
    "df = df[~((df.chain_2.str.contains('\\W', na=False)) & (df.chain_2 != '-1'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protvec = word2vec.Word2Vec.load('model/protvec.model')\n",
    "smilesvec = word2vec.Word2Vec.load('model/smilesvec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = list(df.columns.values)\n",
    "new_cols.extend(pv_col_name)\n",
    "new_cols.extend(sv_col_name)\n",
    "new_cols.extend(dc_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protvec_has_vocab(protvec, chain):\n",
    "    for vv in biovec.utils.split_ngrams(chain, 3):\n",
    "        for v in vv:\n",
    "            if v not in protvec.wv.vocab:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def protvec_online_train(protvec, chain):\n",
    "    corpus = biovec.utils.split_ngrams(chain, 3)\n",
    "    protvec.build_vocab(corpus, update=True)\n",
    "    protvec.train(corpus, epochs=protvec.epochs, total_examples=protvec.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = []\n",
    "feat = RDKitDescriptors()\n",
    "for i, row in tqdm.tqdm(df.iterrows()):\n",
    "    mol = Chem.MolFromSmiles(row.ligand_smiles) #checking validity of SMILES string\n",
    "    if not mol:\n",
    "        continue\n",
    "    pv = np.zeros(100)\n",
    "    for name in chain_col_name:\n",
    "        chain = row[name]\n",
    "        if chain != '-1':\n",
    "            if not protvec_has_vocab(protvec, chain):\n",
    "                protvec_online_train(protvec, chain)\n",
    "            pv += np.sum(protvec.to_vecs(chain), axis=0)\n",
    "\n",
    "    smiles = row['ligand_smiles']\n",
    "    if not smilesvec.has_vocab(smiles):\n",
    "        smilesvec.online_train([smiles])\n",
    "    sv = smilesvec.to_vec(smiles)\n",
    "    \n",
    "    dc = feat.featurize([mol])\n",
    "    \n",
    "    ll.append(np.concatenate([row, pv, sv, dc[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.vstack(ll)\n",
    "del ll\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame(arr)\n",
    "del arr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['n_protein_chains'] + chain_col_name\n",
    "full_df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'id': np.int32, 'Ki': np.float64, 'Ki_r': np.int8, 'IC50': np.float64, 'IC50_r': np.int8, \n",
    "         'Kd': np.float64, 'Kd_r': np.int8, 'EC50': np.float64, 'EC50_r': np.int8, 'pH': np.float16, \n",
    "         'temp': np.float16, 'molwt': np.float16}\n",
    "for c in pv_col_name + sv_col_name + dc_col_name:\n",
    "    types[c] = np.float32\n",
    "\n",
    "full_df = full_df.astype(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(full_df, open('data/dtba_prediction/featured_bindingdb', 'wb+'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
