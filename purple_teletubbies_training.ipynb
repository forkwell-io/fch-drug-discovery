{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mypackages.purple_teletubbies.purple_teletubbies as purple_teletubbies # =)\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pickle.load(open('data/dtba_prediction/featured_bindingdb', 'rb'))\n",
    "\n",
    "feature = 'Kd'\n",
    "drop_uncertain = True\n",
    "classification = False\n",
    "\n",
    "df_full.dropna(subset=[feature], inplace=True)\n",
    "df_full.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "fig.set_figwidth(23)\n",
    "fig.suptitle('Distribution of Label', fontsize=18)\n",
    "ax1.hist(df_full[feature], bins=50)\n",
    "ax1.set_ylabel('count')\n",
    "ax1.set_xlabel('Kd (nM)')\n",
    "\n",
    "df_full.loc[df_full[feature]==0, feature] = 1e-9\n",
    "df_full[feature] = -np.log10(df_full[feature])\n",
    "ax2.hist(df_full[feature], bins=50)\n",
    "ax2.set_xlabel('pKd')\n",
    "\n",
    "if drop_uncertain:\n",
    "    df_full = df_full[df_full[feature+'_r'] == 0]\n",
    "\n",
    "ax3.hist(df_full[feature], bins=50)\n",
    "ax3.set_xlabel('pKd (after dropping uncertained values)')\n",
    "\n",
    "df_full['active'] = ((df_full[feature]+df_full[feature+'_r']) > -3).map({True: 1, False: 0}).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_col = ['dc_'+str(i) for i in range(1, 112)]\n",
    "sv_col = ['sv_'+str(i) for i in range(1, 101)]\n",
    "pv_col = ['sv_'+str(i) for i in range(1, 101)]\n",
    "\n",
    "df_full = df_full.sample(frac=1, replace=False, random_state=666).reset_index(drop=True)\n",
    "X = df_full.drop(['id', 'ligand_smiles', 'target_name', 'Ki', 'IC50', 'Kd', 'EC50', 'active', 'Ki_r', 'Kd_r', 'IC50_r', 'pH', 'temp', 'EC50_r', 'dc_10', 'dc_11', 'dc_12', 'dc_13', 'dc_29'], axis=1).values\n",
    "if classification:\n",
    "    y = df_full['active'].values.reshape(-1, 1)\n",
    "else:\n",
    "    y = df_full[feature].astype(np.float64).values.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('using GPU')\n",
    "    device = torch.device('cuda')\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "input_size = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, X_traini, y_traini, BATCH_SIZE, EPOCH, early_stop=True):\n",
    "    if classification:\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_traini, y_traini, test_size=0.2, random_state=123)\n",
    "    \n",
    "    standardscaler = StandardScaler()\n",
    "    X_train = torch.from_numpy(standardscaler.fit_transform(X_train))\n",
    "    X_val = torch.from_numpy(standardscaler.transform(X_val))\n",
    "    \n",
    "    train = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    all_train_loss = []\n",
    "    all_val_loss = []\n",
    "    if torch.cuda.is_available():\n",
    "        print('using GPU')\n",
    "        device = torch.device('cuda')\n",
    "        model = model.to(device)\n",
    "        criterion = criterion.to(device)\n",
    "    \n",
    "    best = 99999999999\n",
    "    early_stopping_count = 0\n",
    "    for epoch in range(EPOCH):\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for X_train, y_train in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_train.float(), True)\n",
    "            loss = criterion(y_pred.double(), y_train.double())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        all_train_loss.append(train_loss)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_val.float())\n",
    "            val_loss = criterion(y_pred.double(), y_val.double())\n",
    "            if val_loss < best:\n",
    "                best = val_loss\n",
    "                early_stopping_count = 0\n",
    "            elif early_stop:\n",
    "                early_stopping_count += 1\n",
    "                if early_stopping_count >= 20:\n",
    "                    break\n",
    "        all_val_loss.append(val_loss)\n",
    "        print(f'epoch {epoch}: \\ntrain_loss: {train_loss}\\nval_loss: {val_loss}\\n============================================================')\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    ax = plt.plot(list(range(len(all_train_loss))), np.array(all_train_loss), label='train_loss')\n",
    "    plt.plot(list(range(len(all_val_loss))), np.array(all_val_loss), label='val_loss')\n",
    "    plt.title('Training and Validation Loss', fontsize=18)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('MSELoss')\n",
    "    plt.legend()\n",
    "    return standardscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7423)\n",
    "model = purple_teletubbies()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00007)\n",
    "standardscaler = train_model(model, optimizer, X_train, y_train, 512, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.from_numpy(standardscaler.transform(X_test))\n",
    "F.mse_loss(model(X_test.float()), y_test.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(standardscaler, open('model/standardscaler', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/purple_teletubbies.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
